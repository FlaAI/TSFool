{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4cc8c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Dataset Information ***\n",
      "train_x: (135, 150, 1) \n",
      "train_y: (135,) \n",
      "test_x: (316, 150, 1) \n",
      "test_y: (316,)\n",
      "\n",
      "*** Model Information ***\n",
      " RNN(\n",
      "  (rnn): LSTM(1, 128, num_layers=2, batch_first=True)\n",
      "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
      ") \n",
      "\n",
      "*** Training Information ***\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-826da256effe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# clear gradients for this training step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m# backward and compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# apply gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import copy\n",
    "import time\n",
    "\n",
    "torch.manual_seed(1)                      # reproducible\n",
    "torch.set_printoptions(threshold=np.inf)  # print all\n",
    "\n",
    "\n",
    "# ----- Step 1: Set Hyper Parameters ----- #\n",
    "\n",
    "model = 'LSTM'\n",
    "dataset = 'GunPointMaleVersusFemale'\n",
    "NAME = f'{model}-UCR-{dataset}'\n",
    "\n",
    "train_data_path = f'../Datasets/UCR/{dataset}/{dataset}_TRAIN.tsv'\n",
    "test_data_path = f'../Datasets/UCR/{dataset}/{dataset}_TEST.tsv'\n",
    "\n",
    "BATCH_SIZE = 200  # 150\n",
    "LR = 0.001\n",
    "\n",
    "TIME_STEP = 150\n",
    "INPUT_SIZE = 1\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "\n",
    "# ----- Step 2: Dataset Loading and Preprocessing ----- #\n",
    "\n",
    "class GetLoader(torch.utils.data.Dataset):      # 定义GetLoader类，继承Dataset方法\n",
    "\n",
    "    def __init__(self, data_root, data_label):  # 初始化，加载数据\n",
    "        self.data = data_root\n",
    "        self.label = data_label\n",
    "\n",
    "    def __getitem__(self, index):               # index是根据batchsize划分数据得到的索引\n",
    "        data = self.data[index]\n",
    "        labels = self.label[index]\n",
    "        return data, labels\n",
    "\n",
    "    def __len__(self):                          # 返回数据大小长度，方便DataLoader划分\n",
    "        return len(self.data)\n",
    "\n",
    "    \n",
    "train_text = ''\n",
    "test_text = ''\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "\n",
    "with open(train_data_path, 'r') as f:\n",
    "    train_text = f.read()\n",
    "train_lines = train_text.split('\\n')\n",
    "for line in train_lines:\n",
    "    _list = line.split('\\t')\n",
    "    if len(_list) > 1:\n",
    "        train_y.append(float(_list[0])-1)\n",
    "        flo_list = [[float(num)] for num in _list[1:]]\n",
    "        train_x.append(flo_list)\n",
    "\n",
    "with open(test_data_path, 'r') as f:\n",
    "    test_text = f.read()\n",
    "test_lines = test_text.split('\\n')\n",
    "for line in test_lines:\n",
    "    _list = line.split('\\t')\n",
    "    if len(_list) > 1:\n",
    "        test_y.append(float(_list[0])-1)\n",
    "        flo_list = [[float(num)] for num in _list[1:]]\n",
    "        test_x.append(flo_list)\n",
    "        \n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "# for i in range(len(train_y)):  # special pre-processing bacause of the format of the original dataset\n",
    "#     if train_y[i] == -1:\n",
    "#         train_y[i] = 1\n",
    "        \n",
    "# for i in range(len(test_y)):\n",
    "#     if test_y[i] == -1:\n",
    "#         test_y[i] = 1\n",
    "\n",
    "print('*** Dataset Information ***\\ntrain_x:', train_x.shape, '\\ntrain_y:', train_y.shape, '\\ntest_x:', test_x.shape, '\\ntest_y:', test_y.shape)\n",
    "\n",
    "\n",
    "# 留作每50轮输出当前训练结果用\n",
    "train_X = copy.deepcopy(train_x)\n",
    "train_X = torch.from_numpy(train_X).to(torch.float32)\n",
    "train_Y = copy.deepcopy(train_y)\n",
    "test_X = torch.from_numpy(test_x).to(torch.float32)\n",
    "test_Y = test_y\n",
    "\n",
    "train_x = torch.from_numpy(train_x).to(torch.float32)\n",
    "train_y = torch.from_numpy(train_y).to(torch.long)\n",
    "train_data = GetLoader(train_x, train_y)                # 返回Dataset对象(包含data和label)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "train_Y1 = copy.deepcopy(train_y)\n",
    "\n",
    "\n",
    "# ----- Step 3: Create Model Class ----- #\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=128,\n",
    "            num_layers=2,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out = nn.Linear(128, OUTPUT_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)  # None represents zero initial hidden state\n",
    "        out = self.out(r_out[:, -1, :])        # choose r_out at the last time step\n",
    "        return out\n",
    "\n",
    "\n",
    "# ----- Step 4: Instantiate ----- #\n",
    "\n",
    "rnn = RNN()\n",
    "print('\\n*** Model Information ***\\n', rnn, '\\n\\n*** Training Information ***')\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)\n",
    "loss_fn = nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
    "\n",
    "\n",
    "# ----- Step 5: Model Training ----- #\n",
    "\n",
    "for turns in range(1, 201):\n",
    "    for batch_idx, (train_x, train_y) in enumerate(train_loader):\n",
    "        \n",
    "        train_x = train_x.view(-1, TIME_STEP, INPUT_SIZE)\n",
    "        output = rnn(train_x)\n",
    "        loss = loss_fn(output, train_y)\n",
    "        optimizer.zero_grad()  # clear gradients for this training step\n",
    "        loss.backward()        # backward and compute gradients\n",
    "        optimizer.step()       # apply gradients\n",
    "\n",
    "        train_output = rnn(train_X)\n",
    "        pred_train_y = torch.max(train_output, 1)[1].data.numpy()\n",
    "        train_accuracy = float((pred_train_y == train_Y).astype(int).sum()) / float(train_Y.size)\n",
    "        train_loss = loss_fn(train_output, train_Y1)\n",
    "\n",
    "        torch.save(rnn, f'../Models/{NAME}/epoch_{turns}_{batch_idx}.pkl')\n",
    "        print('Epoch: ', turns, '_', batch_idx, '| train loss: %.4f' % train_loss.data.numpy(), '| train accuracy: %.2f' % train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1515152d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** The Optimum Model ***\n",
      "Epoch Index:  200 _ 0\n",
      "Train Loss: 0.184646 \n",
      "Train Accuracy: 0.9630 \n",
      "Test Accuracy: 0.9652\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Finding The Optimum Model Automatically\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "min_loss = 10000\n",
    "max_test_acc = 0\n",
    "corresponding_train_acc = 0\n",
    "\n",
    "turns_chosen = -1\n",
    "batch_idx_chosen = -1\n",
    "\n",
    "for turns in range(198, 201):\n",
    "    batch_number = int(train_X.shape[0]/BATCH_SIZE)\n",
    "    if train_X.shape[0] % BATCH_SIZE != 0:\n",
    "        batch_number += 1\n",
    "    \n",
    "    for batch_idx in range(batch_number):\n",
    "        rnn = torch.load(f'../Models/{NAME}/epoch_{turns}_{batch_idx}.pkl')\n",
    "        \n",
    "        train_output = rnn(train_X)\n",
    "        pred_train_y = torch.max(train_output, 1)[1].data.numpy()\n",
    "        train_accuracy = float((pred_train_y == train_Y).astype(int).sum()) / float(train_Y.size)\n",
    "        train_loss = loss_fn(train_output, train_Y1)\n",
    "        \n",
    "        test_output = rnn(test_X)\n",
    "        pred_test_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "        test_accuracy = float((pred_test_y == test_Y).astype(int).sum()) / float(test_Y.size)\n",
    "        \n",
    "        test_acc_bias = test_accuracy - max_test_acc\n",
    "        loss_bias = train_loss.data.numpy() - min_loss\n",
    "        if test_acc_bias >= 0.01 or (test_acc_bias >= 0 and test_acc_bias < 0.01 and loss_bias < 0.1):\n",
    "            max_test_acc = test_accuracy\n",
    "            min_loss = train_loss.data.numpy()\n",
    "            corresponding_train_acc = train_accuracy\n",
    "            turns_chosen = turns\n",
    "            batch_idx_chosen = batch_idx\n",
    "\n",
    "print('*** The Optimum Model ***\\nEpoch Index: ', turns_chosen, '_', batch_idx_chosen)\n",
    "print('Train Loss: %.6f' % min_loss, '\\nTrain Accuracy: %.4f' % corresponding_train_acc, '\\nTest Accuracy: %.4f' % max_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "134afe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** FGSM ***\n",
      "\n",
      " Average Time Cost: 0.009462118148803711\n",
      "\n",
      " Success Rate of Adversarial Attack: 52.59 %\n",
      "\n",
      " Attacked RNN Test Accuracy: 0.8182\n",
      "\n",
      " Average Perturbation: tensor(90923.5000)\n",
      "\n",
      "*** DeepFool ***\n",
      "\n",
      " DeepFool_average_time_cost: 3.9390298348885997\n",
      "\n",
      " Success Rate of Adversarial Attack: 55.56 %\n",
      "\n",
      " Attacked RNN Test Accuracy: 0.8093\n",
      "\n",
      " Average Perturbation: tensor(88987.5156)\n"
     ]
    }
   ],
   "source": [
    "import torchattacks\n",
    "\n",
    "\n",
    "print('*** FGSM ***')\n",
    "\n",
    "FGSM_time_part_start = time.time()\n",
    "attack_FGSM = torchattacks.FGSM(rnn, eps=0.007)\n",
    "adv_X_FGSM = attack_FGSM(train_X, torch.from_numpy(train_Y).to(torch.long))\n",
    "FGSM_time_part_stop = time.time()\n",
    "FGSM_average_time_cost = (FGSM_time_part_stop - FGSM_time_part_start) / adv_X_FGSM.shape[0]\n",
    "print('\\n Average Time Cost:', FGSM_average_time_cost)\n",
    "\n",
    "adv_output_FGSM = rnn(adv_X_FGSM)\n",
    "pred_adv_y_FGSM = torch.max(adv_output_FGSM, 1)[1].data.numpy()\n",
    "adv_accuracy_FGSM = float((pred_adv_y_FGSM == train_Y).astype(int).sum()) / float(train_Y.size)\n",
    "print('\\n Success Rate of Adversarial Attack: %.2f' % ((1-adv_accuracy_FGSM)*100), '%')\n",
    "\n",
    "test_acc_num = (pred_test_y == test_Y).astype(int).sum()\n",
    "adv_acc_num_FGSM = (pred_adv_y_FGSM == train_Y).astype(int).sum()\n",
    "test_adv_total_num_FGSM = test_Y.size + train_Y.size\n",
    "attacked_test_accuracy_FGSM = float(test_acc_num + adv_acc_num_FGSM) / float(test_adv_total_num_FGSM)\n",
    "print('\\n Attacked RNN Test Accuracy: %.4f' % attacked_test_accuracy_FGSM)\n",
    "\n",
    "sum_distance = 0\n",
    "for i in range(train_X.shape[0]):\n",
    "    for j in range(train_X.shape[1]):\n",
    "        sum_distance += abs(adv_X_FGSM[i, j, 0] - train_X[i, j, 0])\n",
    "average_distance = sum_distance / train_X.shape[0]\n",
    "print('\\n Average Perturbation:', average_distance)\n",
    "\n",
    "\n",
    "# print('\\n*** FAB ***')\n",
    "\n",
    "# FAB_time_part_start = time.time()\n",
    "# attack_FAB = torchattacks.FAB(rnn, norm='Linf', steps=1, eps=None, n_restarts=1, alpha_max=0.1, eta=1.05, beta=0.9, verbose=False, seed=0, targeted=False, n_classes=2)\n",
    "# adv_X_FAB = attack_FAB(train_X, torch.from_numpy(train_Y).to(torch.long))\n",
    "# FAB_time_part_stop = time.time()\n",
    "# FAB_average_time_cost = (FAB_time_part_stop - FAB_time_part_start) / adv_X_FAB.shape[0]\n",
    "# print('\\n FAB_average_time_cost:', FAB_average_time_cost)\n",
    "\n",
    "# adv_output_FAB = rnn(adv_X_FAB)\n",
    "# pred_adv_y_FAB = torch.max(adv_output_FAB, 1)[1].data.numpy()\n",
    "# adv_accuracy_FAB = float((pred_adv_y_FAB == train_Y).astype(int).sum()) / float(train_Y.size)\n",
    "# print('\\n Success Rate of Adversarial Attack: %.2f' % ((1-adv_accuracy_FAB)*100), '%')\n",
    "\n",
    "\n",
    "# test_acc_num = (pred_test_y == test_Y).astype(int).sum()\n",
    "# adv_acc_num_FAB = (pred_adv_y_FAB == train_Y).astype(int).sum()\n",
    "# test_adv_total_num_FAB = test_Y.size + train_Y.size\n",
    "# attacked_test_accuracy_FAB = float(test_acc_num + adv_acc_num_FAB) / float(test_adv_total_num_FAB)\n",
    "# print('\\n Attacked RNN Test Accuracy: %.4f' % attacked_test_accuracy_FAB)\n",
    "\n",
    "# sum_distance = 0\n",
    "# for i in range(train_X.shape[0]):\n",
    "#     for j in range(train_X.shape[1]):\n",
    "#         sum_distance += abs(adv_X_FAB[i, j, 0] - train_X[i, j, 0])\n",
    "# average_distance = sum_distance / train_X.shape[0]\n",
    "# print('\\n Average Perturbation:', average_distance)\n",
    "\n",
    "\n",
    "print('\\n*** DeepFool ***')\n",
    "\n",
    "DeepFool_time_part_start = time.time()\n",
    "attack_DeepFool = torchattacks.DeepFool(rnn, steps=50, overshoot=0.02)\n",
    "adv_X_DeepFool = attack_DeepFool(train_X, torch.from_numpy(train_Y).to(torch.long))\n",
    "DeepFool_time_part_stop = time.time()\n",
    "DeepFool_average_time_cost = (DeepFool_time_part_stop - DeepFool_time_part_start) / adv_X_DeepFool.shape[0]\n",
    "print('\\n DeepFool_average_time_cost:', DeepFool_average_time_cost)\n",
    "\n",
    "adv_output_DeepFool = rnn(adv_X_DeepFool)\n",
    "pred_adv_y_DeepFool = torch.max(adv_output_DeepFool, 1)[1].data.numpy()\n",
    "adv_accuracy_DeepFool = float((pred_adv_y_DeepFool == train_Y).astype(int).sum()) / float(train_Y.size)\n",
    "print('\\n Success Rate of Adversarial Attack: %.2f' % ((1-adv_accuracy_DeepFool)*100), '%')\n",
    "\n",
    "test_acc_num = (pred_test_y == test_Y).astype(int).sum()\n",
    "adv_acc_num_DeepFool = (pred_adv_y_DeepFool == train_Y).astype(int).sum()\n",
    "test_adv_total_num_DeepFool = test_Y.size + train_Y.size\n",
    "attacked_test_accuracy_DeepFool = float(test_acc_num + adv_acc_num_DeepFool) / float(test_adv_total_num_DeepFool)\n",
    "print('\\n Attacked RNN Test Accuracy: %.4f' % attacked_test_accuracy_DeepFool)\n",
    "\n",
    "sum_distance = 0\n",
    "for i in range(train_X.shape[0]):\n",
    "    for j in range(train_X.shape[1]):\n",
    "        sum_distance += abs(adv_X_DeepFool[i, j, 0] - train_X[i, j, 0])\n",
    "average_distance = sum_distance / train_X.shape[0]\n",
    "print('\\n Average Perturbation:', average_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3d845df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " FGSM Distance Rate: tensor(1.0213)\n",
      "\n",
      " DeepFool Distance Rate: tensor(1.0217)\n"
     ]
    }
   ],
   "source": [
    "# Over All\n",
    "\n",
    "self_count = 0\n",
    "other_count = 0\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    for k in range(train_X.shape[0]):\n",
    "        if train_Y[i] == train_Y[k]:\n",
    "            self_count += 1\n",
    "            for j in range(train_X.shape[1]):\n",
    "                self_distance += abs(adv_X_FGSM[i, j, 0] - train_X[k, j, 0])\n",
    "        else:\n",
    "            other_count += 1\n",
    "            for j in range(train_X.shape[1]):\n",
    "                other_distance += abs(adv_X_FGSM[i, j, 0] - train_X[k, j, 0])\n",
    "    \n",
    "distance_rate = (self_distance/self_count) / (other_distance/other_count)\n",
    "print('\\n FGSM Distance Rate:', distance_rate)\n",
    "\n",
    "\n",
    "self_count = 0\n",
    "other_count = 0\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    for k in range(train_X.shape[0]):\n",
    "        if train_Y[i] == train_Y[k]:\n",
    "            self_count += 1\n",
    "            for j in range(train_X.shape[1]):\n",
    "                self_distance += abs(adv_X_DeepFool[i, j, 0] - train_X[k, j, 0])\n",
    "        else:\n",
    "            other_count += 1\n",
    "            for j in range(train_X.shape[1]):\n",
    "                other_distance += abs(adv_X_DeepFool[i, j, 0] - train_X[k, j, 0])\n",
    "    \n",
    "distance_rate = (self_distance/self_count) / (other_distance/other_count)\n",
    "print('\\n DeepFool Distance Rate:', distance_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8419ea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " FGSM Distance Rate: tensor(1.3872)\n",
      "\n",
      " DeepFool Distance Rate: tensor(1.3586)\n"
     ]
    }
   ],
   "source": [
    "# Only Adv\n",
    "\n",
    "self_count = 0\n",
    "other_count = 0\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    if pred_adv_y_FGSM[i] == train_Y[i]:\n",
    "        continue\n",
    "    for k in range(train_X.shape[0]):\n",
    "        if train_Y[i] == train_Y[k]:\n",
    "            self_count += 1\n",
    "            for j in range(train_X.shape[1]):\n",
    "                self_distance += abs(adv_X_FGSM[i, j, 0] - train_X[k, j, 0])\n",
    "        else:\n",
    "            other_count += 1\n",
    "            for j in range(train_X.shape[1]):\n",
    "                other_distance += abs(adv_X_FGSM[i, j, 0] - train_X[k, j, 0])\n",
    "    \n",
    "distance_rate = (self_distance/self_count) / (other_distance/other_count)\n",
    "print('\\n FGSM Distance Rate:', distance_rate)\n",
    "\n",
    "\n",
    "self_count = 0\n",
    "other_count = 0\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    if pred_adv_y_DeepFool[i] == train_Y[i]:\n",
    "        continue\n",
    "    for k in range(train_X.shape[0]):\n",
    "        if train_Y[i] == train_Y[k]:\n",
    "            self_count += 1\n",
    "            for j in range(train_X.shape[1]):\n",
    "                self_distance += abs(adv_X_DeepFool[i, j, 0] - train_X[k, j, 0])\n",
    "        else:\n",
    "            other_count += 1\n",
    "            for j in range(train_X.shape[1]):\n",
    "                other_distance += abs(adv_X_DeepFool[i, j, 0] - train_X[k, j, 0])\n",
    "    \n",
    "distance_rate = (self_distance/self_count) / (other_distance/other_count)\n",
    "print('\\n DeepFool Distance Rate:', distance_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c62746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(115009.9297)\n",
      "tensor(51479.6211)\n",
      "\n",
      " FGSM Distance Rate: tensor(0.6205)\n",
      "\n",
      " DeepFool Distance Rate: tensor(0.6313)\n"
     ]
    }
   ],
   "source": [
    "# Standard Range Distance\n",
    "\n",
    "low_0 = 16776960\n",
    "high_0 = 0\n",
    "low_1 = 16776960\n",
    "high_1 = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    current_sample = 0\n",
    "    for j in range(train_X.shape[1]):\n",
    "        current_sample += train_X[i, j, 0]\n",
    "    \n",
    "    if train_Y[i] == 0:\n",
    "        if current_sample > high_0:\n",
    "            high_0 = current_sample\n",
    "        if current_sample < low_0:\n",
    "            low_0 = current_sample\n",
    "            \n",
    "    if train_Y[i] == 1:\n",
    "        if current_sample > high_1:\n",
    "            high_1 = current_sample\n",
    "        if current_sample < low_1:\n",
    "            low_1 = current_sample\n",
    "\n",
    "range_distance_0 = high_0 - low_0\n",
    "range_distance_1 = high_1 - low_1\n",
    "\n",
    "print(range_distance_0)\n",
    "print(range_distance_1)\n",
    "\n",
    "\n",
    "# Only Adv\n",
    "\n",
    "self_count = 0\n",
    "other_count = 0\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    if pred_adv_y_FGSM[i] == train_Y[i]:\n",
    "        continue\n",
    "    \n",
    "    if train_Y[i] == 0:\n",
    "        self_range_distance = range_distance_0\n",
    "        other_range_distance = range_distance_1\n",
    "    else:\n",
    "        self_range_distance = range_distance_1\n",
    "        other_range_distance = range_distance_0\n",
    "    \n",
    "    for k in range(train_X.shape[0]):\n",
    "        if train_Y[i] == train_Y[k]:\n",
    "            self_count += 1\n",
    "            current_self_distance = 0\n",
    "            for j in range(train_X.shape[1]):\n",
    "                current_self_distance += abs(adv_X_FGSM[i, j, 0] - train_X[k, j, 0])\n",
    "            self_distance += current_self_distance / self_range_distance                \n",
    "        else:\n",
    "            other_count += 1\n",
    "            current_other_distance = 0\n",
    "            for j in range(train_X.shape[1]):\n",
    "                current_other_distance += abs(adv_X_FGSM[i, j, 0] - train_X[k, j, 0])\n",
    "            other_distance += current_other_distance / other_range_distance     \n",
    "\n",
    "distance_rate = (self_distance/self_count) / (other_distance/other_count)\n",
    "print('\\n FGSM Distance Rate:', distance_rate)\n",
    "\n",
    "\n",
    "self_count = 0\n",
    "other_count = 0\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    if pred_adv_y_DeepFool[i] == train_Y[i]:\n",
    "        continue\n",
    "    \n",
    "    if train_Y[i] == 0:\n",
    "        self_range_distance = range_distance_0\n",
    "        other_range_distance = range_distance_1\n",
    "    else:\n",
    "        self_range_distance = range_distance_1\n",
    "        other_range_distance = range_distance_0\n",
    "    \n",
    "    for k in range(train_X.shape[0]):\n",
    "        if train_Y[i] == train_Y[k]:\n",
    "            self_count += 1\n",
    "            current_self_distance = 0\n",
    "            for j in range(train_X.shape[1]):\n",
    "                current_self_distance += abs(adv_X_DeepFool[i, j, 0] - train_X[k, j, 0])\n",
    "            self_distance += current_self_distance / self_range_distance                \n",
    "        else:\n",
    "            other_count += 1\n",
    "            current_other_distance = 0\n",
    "            for j in range(train_X.shape[1]):\n",
    "                current_other_distance += abs(adv_X_DeepFool[i, j, 0] - train_X[k, j, 0])\n",
    "            other_distance += current_other_distance / other_range_distance     \n",
    "\n",
    "distance_rate = (self_distance/self_count) / (other_distance/other_count)\n",
    "print('\\n DeepFool Distance Rate:', distance_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05bdaca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEGCAYAAACevtWaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAuiElEQVR4nO3deXxU5dnw8d+VmewJkI01YIIGEBBBomjFlSLUDdSitPpIrVWft9alrW+L1del1hb72PrYVmpxaWmLIHWlFbeCVnHDoChhRwkQCBACIYFsk8z1/nEOwyBZJjBhJpPr+/nMZ865z33OuWaSuebMfc65b1FVjDHGxJa4SAdgjDEm/Cy5G2NMDLLkbowxMciSuzHGxCBL7sYYE4O8kQ4AIDs7W/Py8iIdhjHGdCrLli3bpao5zS2LiuSel5dHUVFRpMMwxphORUQ2tbTMmmWMMSYGWXI3xpgYZMndGGNiUFS0uRtjYp/P56O0tJS6urpIh9LpJCUlkZubS3x8fMjrWHI3xhwTpaWlpKenk5eXh4hEOpxOQ1WpqKigtLSU/Pz8kNezZhljzDFRV1dHVlaWJfZ2EhGysrLa/YvHkrsx5pixxH5kjuR9Cym5i8gPRWSliBSLyFwRSRKRTBF5U0TWu88ZQfXvFJENIrJWRCa0OypjjDFHpc3kLiL9gFuBQlUdDniAqcB0YJGqFgCL3HlEZKi7fBgwEZgpIp6OCd8YY9qntLSUSZMmUVBQwPHHH89tt91GQ0PDYfW2bdvGN7/5zTa3d+GFF1JZWXlEsdx33308/PDDR7RuW0JtlvECySLiBVKAbcAkYLa7fDYw2Z2eBMxT1XpV3QhsAE4LW8TGGHOEVJXLL7+cyZMns379etatW8e+ffu46667DqnX2NhI3759ee6559rc5sKFC+nRo0cHRXzk2kzuqroVeBjYDJQBe1X1DaCXqpa5dcqAnu4q/YAtQZsodcsOISI3ikiRiBSVl5cf3aswxpgQLF68mKSkJK677joAPB4PjzzyCE8//TQzZ85kypQpXHLJJVxwwQWUlJQwfPhwAGpqarjyyisZMWIEV111FWPGjAl0mZKXl8euXbsoKSnhxBNP5IYbbmDYsGFccMEF1NbWAvDEE09w6qmncvLJJ3PFFVdQU1PT4a+1zUsh3bb0SUA+UAn8Q0SuaW2VZsoOG8tPVWcBswAKCwttrD9jupC86a902LZLZlzU4rKVK1cyevToQ8q6devGgAEDaGxs5IMPPuDzzz8nMzOTkpKSQJ2ZM2eSkZHB559/TnFxMSNHjmx2++vXr2fu3Lk88cQTXHnllTz//PNcc801XH755dxwww0A3H333Tz11FPccsstR/1aWxNKs8zXgY2qWq6qPuAF4GvADhHpA+A+73TrlwL9g9bPxWnGMcaYiFLVZq88OVA+fvx4MjMzD1u+ZMkSpk6dCsDw4cMZMWJEs9vPz88PJP7Ro0cHviCKi4s566yzOOmkk5gzZw4rV64MzwtqRSjJfTNwuoikiPOujANWAwuAaW6dacDL7vQCYKqIJIpIPlAALA1v2MYY037Dhg07rAfaqqoqtmzZgsfjITU1tdn1VENrXEhMTAxMezweGhsbAfjOd77DH/7wB1asWMG99957TO7SbbNZRlU/EpHngE+ARuBTnOaUNGC+iFyP8wUwxa2/UkTmA6vc+jeralMHxW+M6YRaazrpSOPGjWP69On89a9/5dprr6WpqYkf//jHfOc73yElJaXF9caOHcv8+fM577zzWLVqFStWrGjXfqurq+nTpw8+n485c+bQr99hpyHDLqSrZVT1XlUdoqrDVfW/3CthKlR1nKoWuM+7g+o/qKrHq+pgVX2148I3xpjQiQgvvvgi//jHPygoKGDQoEEkJSXxy1/+stX1vv/971NeXs6IESN46KGHGDFiBN27dw95vw888ABjxoxh/PjxDBky5GhfRkgk1J8bHamwsFBtsA5jYtvq1as58cQTIx3GEWlqasLn85GUlMQXX3zBuHHjWLduHQkJCccshubePxFZpqqFzdW3jsOMMaYNNTU1nHfeefh8PlSVP/7xj8c0sR8JS+7GGNOG9PT0TjcUqHUcZowxMciSuzHGxCBL7sYYE4MsuRtjTAyy5G6M6VJefPFFRIQ1a9YAsHz5chYuXBhY/vbbb/P+++8f8fbT0tKOeN0DnZCFgyV3Y0yXMnfuXMaOHcu8efOA8Cf3aGHJ3RjTZezbt4/33nuPp556innz5tHQ0MA999zDs88+y8iRI3nooYd4/PHHeeSRRxg5ciTvvvsu//znPxkzZgyjRo3i61//Ojt27Ahs67rrruOkk05ixIgRPP/884fsa9euXZxxxhm88sorlJeXc8UVV3Dqqady6qmn8t577wFQUVHBBRdcwKhRo7jppptC7sMmFHaduzHm2OvIsVRbSZAvvfQSEydOZNCgQWRmZlJcXMzPf/5zioqK+MMf/gBAbW0taWlp3HHHHQDs2bOHDz/8EBHhySef5Ne//jW/+c1veOCBB+jevXugn5k9e/YE9rNjxw4uvfRSfvGLXzB+/Hi+/e1v88Mf/pCxY8eyefNmJkyYwOrVq7n//vsZO3Ys99xzD6+88gqzZs0K29tgyd0Y02XMnTuX22+/HYCpU6cyd+5chg0b1uo6paWlXHXVVZSVldHQ0EB+fj4A//73vwNNOwAZGc4w0j6fj3HjxvHYY49xzjnnBOquWrUqULeqqorq6mreeecdXnjhBQAuuuiiwDbCwZK7MaZLqKioYPHixRQXFyMiNDU1ISLcf//9ra53yy238KMf/YhLL72Ut99+m/vuuw9ouW94r9fL6NGjef311wPJ3e/388EHH5CcnHxY/ea2EQ7W5m6MOfZUO+7Rgueee45rr72WTZs2UVJSwpYtW8jPz2fz5s1UV1cH6qWnpx8yv3fv3kAXvbNnzw6UX3DBBYGmHDjYLCMiPP3006xZs4YZM2Y0W3f58uUAnH322cyZMweAV1999ZCmnaNlyd0Y0yXMnTuXyy677JCyK664gu3bt7Nq1SpGjhzJs88+yyWXXMKLL74YOKF63333MWXKFM466yyys7MD6959993s2bOH4cOHc/LJJ/PWW28Flnk8HubNm8dbb73FzJkz+d3vfkdRUREjRoxg6NChPP744wDce++9vPPOO5xyyim88cYbDBgwIGyvt80uf0VkMPBsUNFA4B7gr255HlACXKmqe9x17gSuB5qAW1X19db2YV3+GhP7OnOXv9GgvV3+tnnkrqprVXWkqo4ERgM1wIvAdGCRqhYAi9x5RGQoMBUYBkwEZoqI54hfkTHGmHZrb7PMOOALVd0ETAIONEDNBia705OAee5oTRuBDcBpYYjVGGNMiNqb3KcCc93pXqpaBuA+93TL+wFbgtYpdcuMMV1cNIz81hkdyfsWcnIXkQTgUuAfbVVtpuywyETkRhEpEpGi8vLyUMMwxnRSSUlJVFRUWIJvJ1WloqKCpKSkdq3XnuvcvwF8oqo73PkdItJHVctEpA+w0y0vBfoHrZcLbGsm4FnALHBOqLYramNMp5Obm0tpaSl2MNd+SUlJ5Obmtmud9iT3b3GwSQZgATANmOE+vxxU/oyI/BboCxQAS9sVlTEm5sTHxwfu7jQdL6TkLiIpwHjgpqDiGcB8Ebke2AxMAVDVlSIyH1gFNAI3q2pTWKM2xhjTqpCSu6rWAFlfKavAuXqmufoPAg8edXTGGGOOiN2haowxMciSuzHGxCBL7sYYE4MsuRtjTAyy5G6MMTHIkrsxxsQgS+7GGBODLLkbY0wMsuRujDExyJK7McbEIEvuxhgTgyy5G2NMDLLkbowxMciSuzHGxCBL7sYYE4MsuRtjTAwKKbmLSA8ReU5E1ojIahE5Q0QyReRNEVnvPmcE1b9TRDaIyFoRmdBx4RtjjGlOqEfujwKvqeoQ4GRgNTAdWKSqBcAidx4RGQpMBYYBE4GZIuIJd+DGGGNa1mZyF5FuwNnAUwCq2qCqlcAkYLZbbTYw2Z2eBMxT1XpV3QhsAE4Lb9jGGGNaE8qR+0CgHPiziHwqIk+KSCrQS1XLANznnm79fsCWoPVL3bJDiMiNIlIkIkXl5eVH9SKMMcYcKpTk7gVOAf6oqqOA/bhNMC2QZsr0sALVWapaqKqFOTk5IQVrjDEmNKEk91KgVFU/cuefw0n2O0SkD4D7vDOofv+g9XOBbeEJ1xhjTCjaTO6quh3YIiKD3aJxwCpgATDNLZsGvOxOLwCmikiiiOQDBcDSsEZtjDGmVd4Q690CzBGRBOBL4DqcL4b5InI9sBmYAqCqK0VkPs4XQCNws6o2hT1yY4wxLQopuavqcqCwmUXjWqj/IPDgkYdljDHmaNgdqsYYE4MsuRtjTAyy5G6MMTHIkrsxxsQgS+7GGBODLLkbY0wMsuRujDExyJK7McbEIEvuxhgTgyy5G2NMDLLkbowxMciSuzHGxCBL7sYYE4MsuRtjTAyy5G6MMTEopOQuIiUiskJElotIkVuWKSJvish69zkjqP6dIrJBRNaKyISOCt4YY0zz2nPkfp6qjlTVA4N2TAcWqWoBsMidR0SGAlOBYcBEYKaIeMIYszHGmDaEOsxecyYB57rTs4G3gZ+65fNUtR7YKCIbgNOAD45iX8ZEhKqyo6qe1EQP6UnxqCq79zcA0D05Hq8nDr9fWbujmmWb9tDkV/KzU6nzNVG8rYrahkZy0hPJSU+kZ3oSKQkeahqa2F/f6Dw3NLK/vpGGRj9xcYJHBE/cwYff7+yvqq6R1EQPqYleVMHX5KfJrzQ0+tlb62NvrQ9fk9Lk99PoVxqblOp6p9zvd15Lj5R4+vVIJineg6/JT3K8h8zUBDbtruGTTXvYV99IWqKXVPeRk57Iib3Tyc1IRkQC78mByYZGf+C9GH1cBoV5mYE6qQmeQ9Yxx16oyV2BN0REgT+p6iygl6qWAahqmYj0dOv2Az4MWrfULTuEiNwI3AgwYMCAIwzfmNb5/cqO6jrqfH58TX4aGg8+1zf6qaz1sau6ni937WPz7loyU+Lpl5HMvrpGtuypZfmWykAC69M9iX31jVTXNQa2HyfOh0M1Qi+wHbZW1rJyW1WrdeobG6hwX+/qMnhnXfkR7SslwUO/HsmccXwW5w/pSWFeJmmJR3Msador1Hf7TFXd5ibwN0VkTSt1m/u6Puxf3/2CmAVQWFjYCT4aprPYVlnLkvW7eGd9Oe9/URFIzkerbG/dYWV++89tVk1DE+t37mP9zn389YNNxAkM7t2Nr5/Yk0tP7ktBr/RIhxjzQh0ge5v7vFNEXsRpZtkhIn3co/Y+wE63einQP2j1XGBbGGM2JqDJr2zeXcPm3TUUlezmjZU7WLujOqz7SE/0UtfYhK/JyeSpCR7ivXHsrfUFjtiz0xI4Ld85Oi3ZVYMnThjWtxuZaQmUV9dTXl3Pzup66n1NpCR4A00sKQleUhM8JHjj8Cv41WlS8avS6PcjCBmpCXRL8lLb0MS+hkY8Ing9cXjjBK9H6JYUT4+UeBK9HrxBTTppiV66JccT7xFUYWd1Pdsqa/GrEu+JY199IxX7GuiREs+peRn06Z7sNhM5zUabd9ewalsVu2sOfjkG/0KJ9wgZKQlU1flYsn4XJRX7iffE0eRX6hv9h7yHfoXVZVWsLqvi94s3MPq4DG44K5/xQ3vjibPmm44g2sbvSRFJBeJUtdqdfhP4OTAOqFDVGSIyHchU1Z+IyDDgGZwvgL44J1sLVLWppX0UFhZqUVFReF6R6RJ2VNUx56PNzFu6mZ3V9a3W7ZEST4/keOI9cc7DG0eiJ454r9A9OZ6MlASOy0rhuKxUKmsa2LqnlvSkePr0SGJI73QGZqfRpMqW3TWkJnrpmZ6IiNMe7ldF3HZy41BVqmobWbltL4vX7GTJhl2s21Hd7K+cEbnd+e2VIzmhZ9qxDzQGiMiyoItcDl0WQnIfCLzoznqBZ1T1QRHJAuYDA4DNwBRV3e2ucxfwXaARuF1VX21tH5bcTXu88nkZ//e5z6hpaP54IcEbx5j8TM4qyOasghyG9E63k3sRtq++kSXry1nw2TbeXLUj8CsIICk+jrsuGso1YwbY36mdjiq5HwuW3E0o6nxNPPLmOv70zpeHlGekxDOoVzoDc1I5Z1BPzh6UTUqCnbyLVjur6vjL+yU8+e5GGpoONt+cNziHh745gp7pSRGMrnOx5G46vdeKy3jgX6vZWlkbKDsuK4WfThzC+KG9iPfYzdadzeqyKn747HLWbD94jiQ53sO3xwzgpnMGWpIPgSV306k99tYG/uf1tYeUnTs4h0evGkX3lPgIRWXCoc7XxMOvr+XJJRsPKc9KTWD+f5/B8TnWFt+a1pK7He6YqPbVxJ6ZmsAvJg/nqWmnWmKPAUnxHu6+eCjPfG8MJ/bpFiiv2N/AtU8tZUfV4ZefmtBYcjdR6w+L1x+S2L92fBZv3XEu15x+nF2dEmO+dkI2C28dy5/+azTJ8U5vJVsra5n29FL21voiHF3nZMndRKXfL1rPw2+sC8yfeUKWc7SebEfrsUpEmDCsNzOvOSXw5b1mezU3zC6iztfildSmBZbcTdT53aL1/ObNg4l97AnZPHntqSQnWP9zXcF5g3vy6ytGBOaXluzm1rmf0mS3A7eLJXcTVR7993p++9XEPq3QEnsXc8XoXH524ZDA/BurdvD7xesjGFHnY8ndRI0n3/2SR/59MLGfVeAk9qR4S+xd0Y1nH893z8wPzD+6aD3/OcKOzLoiS+4mKrxWXMaDC1cH5s8qyOaJay2xd3U/u3AIZwzMApx+bW6f9ynbm+nAzRzOkruJuOKte7lt3vJAp1SFx2VYYjcAeD1x/O5bo+iZngjAnhofd/zjM/zW/t4mS+4m4n716upAL4J5WSnMssRuguSkJ/L7b40KDBKyZMMu/vJ+SURj6gwsuZuIWrpxN+9tqADAEyc8Oa2QzNSECEdlos2YgVncdPbxgfkZr63hy/J9EYwo+llyNxH16KKDJ1AvH9WPE3raIA6meT8aP4ih7l2sDY1+Zrza2phBxpK7iZiPSw49av/B+SdEOCITzRK8ccy44qTA/BurdrB04+4IRhTdLLmbiGhs8nP/P1cG5i8b1Y/jslIjGJHpDEbk9mDSyL6B+V8uXE00dH4YjUJO7iLiEZFPReRf7nymiLwpIuvd54yguneKyAYRWSsiEzoicNO5/eX9Eoq3OoM1J3rjuPX8gghHZDqLOy4YTILbxfPyLZUs+MxG8WxOe47cbwNWB81PBxapagHOUHrTAURkKDAVGAZMBGaKiF36YAJK99Twm6B+Y24dV8CArJQIRmQ6k/6ZKVx3Zl5g/pcLV7O/vjFyAUWpkJK7iOQCFwFPBhVPAma707OByUHl81S1XlU3AhtwxlM1BoBfLVxDrdsR1KBeadxw1sAIR2Q6mx+cfwLZac617zuq6vnDWxsiHFH0CfXI/X+BnwDBQ5r3UtUyAPe5p1veD9gSVK/ULTuEiNwoIkUiUlRebrcUdxWfl1byyoqywPwvLzuJBK+d+jHtk54Uz53fONj3zJPvfsnGXfsjGFH0afNTJSIXAztVdVmI22yuo+3Dznio6ixVLVTVwpycnBA3bTq7X792sH/2bwzvTWFeZgSjMZ3ZZaP6ccqAHgD4mpTH7Oj9EKEcMp0JXCoiJcA84HwR+TuwQ0T6ALjPO936pUD/oPVzATvjYViyfhdLNuwCnEsf75gwOMIRmc4sLk742YUnBuZf+nTrIWPsdnVtJndVvVNVc1U1D+dE6WJVvQZYAExzq00DXnanFwBTRSRRRPKBAmBp2CM3nc7vgrpsnTI618bHNEetMC+T0/KdX3+NfuWJd76McETR42gaO2cA40VkPTDenUdVVwLzgVXAa8DNqmrDqHRxxVv3Bm448cYJt46zSx9NeHz/3IPdEsz7eDMV++ojGE30aFdyV9W3VfVid7pCVcepaoH7vDuo3oOqeryqDlbVV8MdtOl8ngoa3f6iEX3o2yM5gtGYWHLOoByG9XW6Jajz+fnzeyWRDShK2GUKpsPtqKrjn0E3mlw/Nr+V2sa0j4jw/XMPdl0x+4MSqutsUG1L7qbD/fWDEhrd/rcLj8tgRG6PyAZkYs7E4b0ZmO10X1Fd18jfP9wc4Ygiz5K76VDVdT7+9sGmwLwdtZuO4IkT/vucg23vTy3ZSJ2va5/qs+RuOtQzH22mqs65NTwvK4ULhvWOcEQmVk0e1Y8+3ZMA2LWvnr9+UBLZgCLMkrvpMHW+Jp4MOpF60znH44lr7h43Y45egjeOm84+2JXFI2+uZ8vumghGFFmW3E2Hef6TUsqrncvSenVL5PJTDuuFwpiwuvr04xjS2xnwpdbXxN0vFXfZLoEtuZsOUedr4rHFB28H/97YgSR6rXNQ07HiPXH86vKTAuOt/mddeZftEtiSu+kQf3m/hG176wDISk3gW2MGRDgi01WMGpDBtDPyAvM//+cq9uxviFxAEWLJ3YTdnv0Nh3TidPvXC0hL9EYwItPV3DFhMH3dk6sV+xt4cOHqNtaIPZbcTdj9fvEGqt0rZAZmpzL1NDtqN8dWWqKXByYPD8w/t6yU/6zrWl2LW3I3YbWpYj9/+7AkMP+TiUOI99i/mTn2xp3Yi4tG9AnM3z7vU0r3dJ2rZ+xTZ8Lqf15fi6/p4N2oE4b1inBEpiu775Jh5KQ7IzbtqfFx09+WdZmbmyy5m7BZvqWSf31+cJSln110IiJ2XbuJnJz0RP549SnEe5z/w5XbqrjzhRVd4vJIS+4mLOp8Tdz90orA/IUn9eaUARkRjMgYR2FeJvdeMiww/+KnW/nL+yWRC+gYseRujpqq8rMXVlC8tQqAeI/wkwlD2ljLmGPn6jEDuKrw4ABxv3hlNS8v3xrBiDpeKGOoJonIUhH5TERWisj9bnmmiLwpIuvd54ygde4UkQ0islZEJnTkCzCRVdPQyC8XruaFTw9+UO6+aCh5bg99xkQDEeHnk4cxsn8PAJr8ym3zlvP9OcvYHaPXwIdy5F4PnK+qJwMjgYkicjowHVikqgXAInceERmKMxzfMGAiMFNE7NbEGFPT0MjfPtzE+Q//hyfePdh/zJWFuVx7xnERjMyY5iV6PTx+zWhyMw4OFLNwxXYu+f0SirfujWBkHSOUMVRVVfe5s/HuQ4FJwGy3fDYw2Z2eBMxT1XpV3QhsAE4LZ9AmMhqb/Hz4ZQX3vFzMGb9azP97qZjtVXWB5WcMzOLnk4bbSVQTtXp3T2LhbWcd0kSztbKWK/74Pn/7oAS/P3ZOtIZ026B75L0MOAF4TFU/EpFeqloGoKplItLTrd4P+DBo9VK37KvbvBG4EWDAALvJ5VjZVLGf14q3s27HPqrrfPgV+vVIon9mCrkZKeSkJ9LQ6GdPTQNf7NzH1spaan1NlFfXs3xLJTUNh19GlpOeyB0XDOKbo/tbr48m6nVLiuehb47g60N78aNnl1Nd30h9o5//9/JKXlu5nfsvHc4JPTv/4O0hJXd3gOuRItIDeFFEhrdSvblP92Ffh6o6C5gFUFhYGDtfl1Hq45Ld/Grhaj7ZXBm2bfbPTOa7Z+ZzZWF/Uq17AdPJjB/aiwW3jOX//H0Za7ZXA/DehgrGP/IfLh7Rl6vHDODUvMxOe8DSrk+kqlaKyNs4bek7RKSPe9TeB9jpVisF+getlgt0zW7ZokB1nY+7Xyrm5eXh+RP07Z7EeUN6ctFJfRgzMKvT/uMbA5CfncpLN5/Jo4vW86f/fIFfQRX++dk2/vnZNnLSEzmpX3dO6JnG6OMyOH1gFt2T4yMddkikrYv5RSQH8LmJPRl4A3gIOAeoUNUZIjIdyFTVn4jIMOAZnHb2vjgnWwvco/9mFRYWalFRUbuDn/L4+9T5/MTFCd44wSOCJ07oluwlMzWBjJQEMlMT6NUtiX4ZyWSmJJCa6CU10UNyvCfm24a3Vtby3T9/zNod1YGyeI9wzqAczhnck+zUBPwKWytr2LK7ltI9Neyu8ZHojSMt0Ut+dip5WSmkJXlJSfAyvF93+vVIbmWPxnReK0r38ts31/LW2tb7oElN8NAtOZ70JC/dkuLpnhxP95R4eiQn0CMlnszUBLLTEshOSyQrLZHstATSEr0dkm9EZJmqFja3LJQj9z7AbLfdPQ6Yr6r/EpEPgPkicj2wGZgCoKorRWQ+sApoBG5uLbEfjeKtVdQe4a3EcQKZqYn06Z5EfnYqI3K7c/rALIb36x7mKCNjdVkV1z69NDBYBsBFI/pw5zeGkJuREsHIjIlOJ+V258/XncbnpZXML9rCqyu2U9HMZZL7G5rY39BEWTsusEn0xtGrWxJ9uifRr0cyfXok0ad7cmA6NyMl7D2ntnnkfiwc6ZH7oLtepaHJH9ZYxp6QzS3nn8CYgVlh3e6x9NmWSq59eil7a32Ac7Q+4/IRXDE6N8KRGdN5NDb52VC+jy927mfF1r28/8UuirfupSMuqLl1XAE/Gj+o3esd7ZF71Hrx5q/R5NdDHr4mparOx+79DezZ30DF/ga2VdaytbKWqjof++ub2O+eHW/Okg27WLJhF1NP7c/dFw/tdP2Qf1yym+v+/DH76p0ud9MTvfzp2tF87fjsCEdmTOfi9cQxpHc3hvTuFuhd0u9X9jU0Ul3XSFWtj6paH3trfVS603tqGqjY18CufQ3s2lcfeNT5Wj8IPdD3fFjjD/sWj6FhfY+8CcXX5Ke8up5tlbWsLqviw427ea14O03u1/K8j7fw/hcVzLz6lE7TVLNk/S5u+GtRoKmqR0o8f/vuGE7K7RzxGxPt4uKEbknxdEuKb9f5p331jWzfW8e2ylrK9tayrfLAdB3b9tYyIDP8TaWdulkm3DZV7GfGq2t4tXh7oCzBG8cvJg/nysL+rawZWVt21/DUko0889HmQDNVdloic743hsHuYMHGmNjTWrOMJfevUFVeWr6Ve15aSbXbtAHw7TEDuPeSoWEd5FlVKa+up2xvHY1+P01+2L2/gfJ99eyqrqdiv/NzrrHJj8+v+Br9NPoVX5OftEQvWWkJrNhaxWdbKg/Zbp/uScz53hgG5nT+GzGMMS2L2Tb3jiAiXDYql5Nze/Dff1/Guh1OzwvPfLSZVduqeHjKCE7o2frRsKpSvLWKok272bK7lor99SR5PSR449hX38ju/Q2U7qmhdE9ti23/R+qkft2ZefUp9O+An3nGmM7Djtxbsb++kZ8+//khA1B44oRvndafCcN6M6hXOrUNTezaV8+miho27a5hy+4aPi7ZTeme2mMWpydOOPOEbL43Np+zCrJj/vp9Y4zDmmWOgqry9Hsl/HLh6sDJ1nDqnuycmEmMjyNOhB7J8WSnJZKd7twEkZLgwRsXR7w3jvg4weuJwxsnVNX5KK+up1e3JM4uyKF7Sue4a84YEz7WLHMURITrx+Y7PR7+ayUffrk7pPXSk7yMG9KTwb270TM9kYYmP3W+JtISvfRISaCv21lXtyRLysaY8LPkHqKhfbsx94bT+c+6chav2cnHJXvYUVXnJut4+mekMCArheMyU8jPTmXUgAwSvDbQlTEmMiy5t4OIcO7gnpw7uGfblY0xJoLs0NIYY2KQJXdjjIlBltyNMSYGWXI3xpgYZMndGGNiUJvJXUT6i8hbIrJaRFaKyG1ueaaIvCki693njKB17hSRDSKyVkQmdOQLMMYYc7hQjtwbgR+r6onA6cDNIjIUmA4sUtUCnKH0pgO4y6YCw3DGWp3pjuJkjDHmGGkzuatqmap+4k5XA6uBfsAkYLZbbTYw2Z2eBMxT1XpV3QhswBlP1RhjzDHSrjZ3EckDRgEfAb1UtQycLwDgwJ09/YAtQauVumVf3daNIlIkIkXl5a0PSGuMMaZ9Qk7uIpIGPA/crqpVrVVtpuywHrdUdZaqFqpqYU5OTqhhGGOMCUFIyV1E4nES+xxVfcEt3iEifdzlfYCdbnkpEDxsUS6wLTzhGmOMCUUoV8sI8BSwWlV/G7RoATDNnZ4GvBxUPlVEEkUkHygAloYvZGOMMW0JpeOwM4H/AlaIyHK37GfADGC+iFwPbAamAKjqShGZD6zCudLmZlVtCnfgxhhjWtZmclfVJTTfjg4wroV1HgQePIq4jDHGHAW7Q9UYY2KQJXdjjIlBltyNMSYGWXI3xpgYZMndGGNikCV3Y4yJQZbcjTEmBllyN8aYGGTJ3RhjYpAld2OMiUGW3I0xJgZZcjfGmBhkyd0YY2KQJXdjjIlBltyNMSYGhTIS09MislNEioPKMkXkTRFZ7z5nBC27U0Q2iMhaEZnQUYEbY4xpWShH7n8BJn6lbDqwSFULgEXuPCIyFJgKDHPXmSkinrBFa4wxJiRtJndVfQfY/ZXiScBsd3o2MDmofJ6q1qvqRmADcFp4QjXGGBOqI21z76WqZQDuc0+3vB+wJaheqVtmjDHmGAr3CdXmxlrVZiuK3CgiRSJSVF5eHuYwjDGmazvS5L5DRPoAuM873fJSoH9QvVxgW3MbUNVZqlqoqoU5OTlHGIYxxpjmHGlyXwBMc6enAS8HlU8VkUQRyQcKgKVHF6Ixxpj28rZVQUTmAucC2SJSCtwLzADmi8j1wGZgCoCqrhSR+cAqoBG4WVWbOih2Y4wxLWgzuavqt1pYNK6F+g8CDx5NUMYYY46O3aFqjDExyJK7McbEIEvuxhgTgyy5G2NMDLLkbowxMciSuzHGxCBL7sYYE4MsuRtjTAyy5G6MMTHIkrsxxsQgS+7GGBODLLkbY0wMsuRujDExyJK7McbEIEvuxhgTgyy5G2NMDGpzsI4jJSITgUcBD/Ckqs4I+04aGkINJnrrhXufxhhDByV3EfEAjwHjcQbN/lhEFqjqqrDuKCMDamrCuskuoSt92Vlska8XiX3GxUF8PHi9ziN42usFjye6Dph+8hO4/PKwbrKjjtxPAzao6pcAIjIPmIQztqqJNNXw1jPGHJ2dO8O+yY5K7v2ALUHzpcCY4AoiciNwI8CAAQOObC/x8c6jNeFOZKHUs+RpjImwjkruzf3eOSSTqeosYBZAYWHhkWW5ysojWi1mReKLJ5q/FC22yNeL1D79fmhsdB4+38HpA/NNTaHt71jJzw/7JjsquZcC/YPmc4FtHbQvc0A42z+NMZ1aR10K+TFQICL5IpIATAUWdNC+jDHGfEWHHLmraqOI/AB4HedSyKdVdWVH7MsYY8zhOuw6d1VdCCzsqO0bY4xpmd2haowxMciSuzHGxCBL7sYYE4MsuRtjTAyy5G6MMTHIkrsxxsQg0Sjo30REyoFNR7GJbGBXmMLpCNEeH1iM4WIxhofFGJrjVDWnuQVRkdyPlogUqWphpONoSbTHBxZjuFiM4WExHj1rljHGmBhkyd0YY2JQrCT3WZEOoA3RHh9YjOFiMYaHxXiUYqLN3RhjzKFi5cjdGGNMEEvuxhgTgzp1cheRiSKyVkQ2iMj0SMcDICL9ReQtEVktIitF5Da3PFNE3hSR9e5zRoTj9IjIpyLyryiNr4eIPCcia9z38owojPGH7t+4WETmikhSpGMUkadFZKeIFAeVtRiTiNzpfn7WisiECMb4P+7f+nMReVFEekRbjEHL7hARFZHsSMbYlk6b3EXEAzwGfAMYCnxLRIZGNioAGoEfq+qJwOnAzW5c04FFqloALHLnI+k2YHXQfLTF9yjwmqoOAU7GiTVqYhSRfsCtQKGqDscZlGZqFMT4F2DiV8qajcn9v5wKDHPXmel+riIR45vAcFUdAawD7ozCGBGR/sB4YHNQWaRibFWnTe7AacAGVf1SVRuAecCkCMeEqpap6ifudDVOUuqHE9tst9psYHJEAgREJBe4CHgyqDia4usGnA08BaCqDapaSRTF6PICySLiBVJwxgmOaIyq+g6w+yvFLcU0CZinqvWquhHYgPO5OuYxquobqtrozn6IM+5yVMXoegT4CRB8JUpEYmxLZ07u/YAtQfOlblnUEJE8YBTwEdBLVcvA+QIAekYwtP/F+Qf1B5VFU3wDgXLgz27T0ZMikhpNMarqVuBhnCO4MmCvqr4RTTEGaSmmaP0MfRd41Z2OmhhF5FJgq6p+9pVFURNjsM6c3KWZsqi5rlNE0oDngdtVtSrS8RwgIhcDO1V1WaRjaYUXOAX4o6qOAvYT+WaiQ7jt1pOAfKAvkCoi10Q2qnaLus+QiNyF07Q550BRM9WOeYwikgLcBdzT3OJmyiKeizpzci8F+gfN5+L8LI44EYnHSexzVPUFt3iHiPRxl/cBdkYovDOBS0WkBKcp63wR+XsUxQfO37ZUVT9y55/DSfbRFOPXgY2qWq6qPuAF4GtRFuMBLcUUVZ8hEZkGXAxcrQdvwImWGI/H+SL/zP3s5AKfiEhvoifGQ3Tm5P4xUCAi+SKSgHNCY0GEY0JEBKeteLWq/jZo0QJgmjs9DXj5WMcGoKp3qmququbhvGeLVfWaaIkPQFW3A1tEZLBbNA5YRRTFiNMcc7qIpLh/83E451eiKcYDWoppATBVRBJFJB8oAJZGID5EZCLwU+BSVa0JWhQVMarqClXtqap57menFDjF/V+NihgPo6qd9gFciHNm/QvgrkjH48Y0Fucn2efAcvdxIZCFc6XCevc5MwpiPRf4lzsdVfEBI4Ei9318CciIwhjvB9YAxcDfgMRIxwjMxTkH4MNJQNe3FhNOU8MXwFrgGxGMcQNOu/WBz8zj0RbjV5aXANmRjLGth3U/YIwxMagzN8sYY4xpgSV3Y4yJQZbcjTEmBllyN8aYGGTJ3RhjYpAldxNRItJLRJ4RkS9FZJmIfCAil4nIuSKy1+1+YLWI3OvWP9ftke/6oG2McsvuEJHviMjcr+wjW0TK3euQ33Z77lvuPr7ZTEzfcet/6vak+LqIfK0DXnueiNQGxbLcvWejvdt5W0SidqBmExneSAdgui735p+XgNmq+m237DjgUmAP8K6qXuz2K7Nc3O6JgRXAVbgdi+HcjHWgv48XgIdFJEUP3gzzTWCBqtY7u+RqVS1qI7xnVfUHbkznAS+IyHmqurqN9drrC1UdGeZtGmNH7iaizgcaVPXxAwWquklVfx9cSVX3A8twbgEH5+7QJPeoX3C6WX3VrVsFvANcErSJqTg3pRwRVX0LZ7zMGwFE5HgRec39pfGuiAxxy3NE5HkR+dh9nOmW3ycifxORxe4vgRta25+IjHN/NawQp1/xxNbKjWmOJXcTScOAT9qqJCJZOH3jrwwqfg6YgtOfyydAfdCyuTgJHRHpCwwC3gpaPieoGSQrxFg/AYa407OAW1R1NHAHMNMtfxR4RFVPBa7g0C6VR+B0s3wGcI8bF8DxQbE8JiJJOH2JX6WqJ+H8uv4/LZWHGLvpgqxZxkQNEXkMp/uGBuD/AmeJyKc4XRPPUNWVInKuW30+8CxOwp2Lk+QP+BfOgAndgCuB51S1KWh5KM0yh4Xnxpjm7usfbhMPON0OgNOZ2NCg8m4iku5Ov6yqtUCtiLyF09/3cr7SLCMiJ+N0SLbOLZoN3Izz5dRc+f+283WYLsKSu4mklThHuACo6s3iDF12IPG+q6oXN7eiqm4XER/OqDi3EZTcVbVWRF4DLsM5gv9ha0GIyM3AgaaSC1uoNgqnY7A4oLKFdvI44Aw3iQdvHw7vAralfj+a6z62tXJjmmXNMiaSFuO0nQc3L6S0Y/17gJ9+5aj8gLnAj4BeOCP7tEhVH1PVke7jsK5aReQcnPb2J9w2/Y0iMsVdJu7RNsAbwA+C1hsZtJlJ4oyxmoXTYdvHLYSzBsgTkRPc+f8C/tNKuTHNsuRuIkadXusmA+eIyEYRWYrT3PDTENd/X1VfamHxGziDaDyrR9Y73lVuO/g64GfAFUFXylwNXC8in+H8+jgwvOOtQKE4gzyvAv47aHtLgVdwvmgeaO5LxH1NdcB1OM0+K3CapB5vqfwIXpfpIqxXSGM6mIjcB+xT1YcjHYvpOuzI3RhjYpAduRtjTAyyI3djjIlBltyNMSYGWXI3xpgYZMndGGNikCV3Y4yJQf8fzY2I7c2xddQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LABEL = 'GPMVF'\n",
    "timestep_record = [i for i in range(train_X.shape[1])]\n",
    "\n",
    "\n",
    "plt.plot(timestep_record, train_X[123], '-', linewidth=3, color='#1f77b4', label='Original')\n",
    "plt.plot(timestep_record, adv_X_DeepFool[123], '-', linewidth=3, color='red', label='Attacked')\n",
    "plt.xlabel(f\"{LABEL}-DeepFool\")\n",
    "plt.ylim(-50, 850)\n",
    "plt.legend()\n",
    "plt.savefig(f'../Savefig/{LABEL}-DeepFool.png', bbox_inches='tight', dpi=600)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b770aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8832)\n",
      "tensor(1.3990)\n"
     ]
    }
   ],
   "source": [
    "print(self_distance/self_count)\n",
    "print(other_distance/other_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea82cbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(49400.4805)\n",
      "tensor(17575.0898)\n",
      "\n",
      " FGSM Cam Rate: tensor(0.4932)\n",
      "tensor(150.5651)\n",
      "tensor(305.3069)\n",
      "\n",
      " DeepFool Cam Rate: tensor(0.5035)\n",
      "tensor(154.5056)\n",
      "tensor(306.8691)\n"
     ]
    }
   ],
   "source": [
    "# Avg Sample and Avg Distance\n",
    "\n",
    "sum_train_X_0 = train_X[0] - train_X[0]\n",
    "sum_train_X_1 = train_X[0] - train_X[0]\n",
    "count_train_X_0 = 0\n",
    "count_train_X_1 = 0\n",
    "for i in range(train_X.shape[0]):\n",
    "    if train_Y[i] == 0:\n",
    "        count_train_X_0 += 1\n",
    "        sum_train_X_0 += train_X[i]\n",
    "    if train_Y[i] == 1:\n",
    "        count_train_X_1 += 1\n",
    "        sum_train_X_1 += train_X[i]\n",
    "avg_train_X_0 = sum_train_X_0 / count_train_X_0\n",
    "avg_train_X_1 = sum_train_X_1 / count_train_X_1\n",
    "\n",
    "distance_train_X_0 = 0\n",
    "distance_train_X_1 = 0\n",
    "for i in range(train_X.shape[0]):\n",
    "    current_distance = 0\n",
    "    if train_Y[i] == 0:\n",
    "        for j in range(train_X.shape[1]):\n",
    "            current_distance += abs(train_X[i, j, 0] - avg_train_X_0[j, 0])\n",
    "        distance_train_X_0 += current_distance\n",
    "    if train_Y[i] == 1:\n",
    "        for j in range(train_X.shape[1]):\n",
    "            current_distance += abs(train_X[i, j, 0] - avg_train_X_1[j, 0])\n",
    "        distance_train_X_1 += current_distance\n",
    "avg_distance_train_X_0 = distance_train_X_0 / count_train_X_0\n",
    "avg_distance_train_X_1 = distance_train_X_1 / count_train_X_1\n",
    "\n",
    "print(avg_distance_train_X_0)\n",
    "print(avg_distance_train_X_1)\n",
    "\n",
    "\n",
    "# Only Adv\n",
    "\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    if pred_adv_y_FGSM[i] == train_Y[i]:\n",
    "        continue\n",
    "\n",
    "    if train_Y[i] == 0:\n",
    "        self_avg_train_X = avg_train_X_0\n",
    "        other_avg_train_X = avg_train_X_1\n",
    "        self_avg_distance = avg_distance_train_X_0\n",
    "        other_avg_distance = avg_distance_train_X_1\n",
    "    else:\n",
    "        self_avg_train_X = avg_train_X_1\n",
    "        other_avg_train_X = avg_train_X_0\n",
    "        self_avg_distance = avg_distance_train_X_1\n",
    "        other_avg_distance = avg_distance_train_X_0\n",
    "\n",
    "    current_self_distance = 0\n",
    "    for j in range(train_X.shape[1]):\n",
    "        current_self_distance += abs(adv_X_FGSM[i, j, 0] - self_avg_train_X[j, 0])\n",
    "    self_distance += current_self_distance / self_avg_distance\n",
    "    \n",
    "    current_other_distance = 0\n",
    "    for j in range(train_X.shape[1]):\n",
    "        current_other_distance += abs(adv_X_FGSM[i, j, 0] - other_avg_train_X[j, 0])\n",
    "    other_distance += current_other_distance / other_avg_distance\n",
    "\n",
    "cam_rate =  self_distance / other_distance\n",
    "print('\\n FGSM Cam Rate:', cam_rate)\n",
    "print(self_distance)\n",
    "print(other_distance)\n",
    "\n",
    "\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    if pred_adv_y_DeepFool[i] == train_Y[i]:\n",
    "        continue\n",
    "\n",
    "    if train_Y[i] == 0:\n",
    "        self_avg_train_X = avg_train_X_0\n",
    "        other_avg_train_X = avg_train_X_1\n",
    "        self_avg_distance = avg_distance_train_X_0\n",
    "        other_avg_distance = avg_distance_train_X_1\n",
    "    else:\n",
    "        self_avg_train_X = avg_train_X_1\n",
    "        other_avg_train_X = avg_train_X_0\n",
    "        self_avg_distance = avg_distance_train_X_1\n",
    "        other_avg_distance = avg_distance_train_X_0\n",
    "\n",
    "    current_self_distance = 0\n",
    "    for j in range(train_X.shape[1]):\n",
    "        current_self_distance += abs(adv_X_DeepFool[i, j, 0] - self_avg_train_X[j, 0])\n",
    "    self_distance += current_self_distance / self_avg_distance\n",
    "    \n",
    "    current_other_distance = 0\n",
    "    for j in range(train_X.shape[1]):\n",
    "        current_other_distance += abs(adv_X_DeepFool[i, j, 0] - other_avg_train_X[j, 0])\n",
    "    other_distance += current_other_distance / other_avg_distance\n",
    "\n",
    "cam_rate =  self_distance / other_distance\n",
    "print('\\n DeepFool Cam Rate:', cam_rate)\n",
    "print(self_distance)\n",
    "print(other_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f6935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
