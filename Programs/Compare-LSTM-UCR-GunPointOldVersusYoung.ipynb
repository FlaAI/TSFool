{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4cc8c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Dataset Information ***\n",
      "train_x: (136, 150, 1) \n",
      "train_y: (136,) \n",
      "test_x: (315, 150, 1) \n",
      "test_y: (315,)\n",
      "\n",
      "*** Model Information ***\n",
      " RNN(\n",
      "  (rnn): LSTM(1, 128, num_layers=2, batch_first=True)\n",
      "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
      ") \n",
      "\n",
      "*** Training Information ***\n",
      "Epoch:  1 _ 0 | train loss: 0.6871 | train accuracy: 0.52\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-372ef5bbf1e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# clear gradients for this training step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m# backward and compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# apply gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import copy\n",
    "import time\n",
    "\n",
    "torch.manual_seed(1)                      # reproducible\n",
    "torch.set_printoptions(threshold=np.inf)  # print all\n",
    "\n",
    "\n",
    "# ----- Step 1: Set Hyper Parameters ----- #\n",
    "\n",
    "model = 'LSTM'\n",
    "dataset = 'GunPointOldVersusYoung'\n",
    "NAME = f'{model}-UCR-{dataset}'\n",
    "\n",
    "train_data_path = f'../Datasets/UCR/{dataset}/{dataset}_TRAIN.tsv'\n",
    "test_data_path = f'../Datasets/UCR/{dataset}/{dataset}_TEST.tsv'\n",
    "\n",
    "BATCH_SIZE = 200  # 150\n",
    "LR = 0.001\n",
    "\n",
    "TIME_STEP = 150\n",
    "INPUT_SIZE = 1\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "\n",
    "# ----- Step 2: Dataset Loading and Preprocessing ----- #\n",
    "\n",
    "class GetLoader(torch.utils.data.Dataset):      # 定义GetLoader类，继承Dataset方法\n",
    "\n",
    "    def __init__(self, data_root, data_label):  # 初始化，加载数据\n",
    "        self.data = data_root\n",
    "        self.label = data_label\n",
    "\n",
    "    def __getitem__(self, index):               # index是根据batchsize划分数据得到的索引\n",
    "        data = self.data[index]\n",
    "        labels = self.label[index]\n",
    "        return data, labels\n",
    "\n",
    "    def __len__(self):                          # 返回数据大小长度，方便DataLoader划分\n",
    "        return len(self.data)\n",
    "\n",
    "    \n",
    "train_text = ''\n",
    "test_text = ''\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "\n",
    "with open(train_data_path, 'r') as f:\n",
    "    train_text = f.read()\n",
    "train_lines = train_text.split('\\n')\n",
    "for line in train_lines:\n",
    "    _list = line.split('\\t')\n",
    "    if len(_list) > 1:\n",
    "        train_y.append(float(_list[0])-1)\n",
    "        flo_list = [[float(num)] for num in _list[1:]]\n",
    "        train_x.append(flo_list)\n",
    "\n",
    "with open(test_data_path, 'r') as f:\n",
    "    test_text = f.read()\n",
    "test_lines = test_text.split('\\n')\n",
    "for line in test_lines:\n",
    "    _list = line.split('\\t')\n",
    "    if len(_list) > 1:\n",
    "        test_y.append(float(_list[0])-1)\n",
    "        flo_list = [[float(num)] for num in _list[1:]]\n",
    "        test_x.append(flo_list)\n",
    "        \n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "# for i in range(len(train_y)):  # special pre-processing bacause of the format of the original dataset\n",
    "#     if train_y[i] == -1:\n",
    "#         train_y[i] = 1\n",
    "        \n",
    "# for i in range(len(test_y)):\n",
    "#     if test_y[i] == -1:\n",
    "#         test_y[i] = 1\n",
    "\n",
    "print('*** Dataset Information ***\\ntrain_x:', train_x.shape, '\\ntrain_y:', train_y.shape, '\\ntest_x:', test_x.shape, '\\ntest_y:', test_y.shape)\n",
    "\n",
    "\n",
    "# 留作每50轮输出当前训练结果用\n",
    "train_X = copy.deepcopy(train_x)\n",
    "train_X = torch.from_numpy(train_X).to(torch.float32)\n",
    "train_Y = copy.deepcopy(train_y)\n",
    "test_X = torch.from_numpy(test_x).to(torch.float32)\n",
    "test_Y = test_y\n",
    "\n",
    "train_x = torch.from_numpy(train_x).to(torch.float32)\n",
    "train_y = torch.from_numpy(train_y).to(torch.long)\n",
    "train_data = GetLoader(train_x, train_y)                # 返回Dataset对象(包含data和label)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "train_Y1 = copy.deepcopy(train_y)\n",
    "\n",
    "\n",
    "# ----- Step 3: Create Model Class ----- #\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=128,\n",
    "            num_layers=2,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out = nn.Linear(128, OUTPUT_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)  # None represents zero initial hidden state\n",
    "        out = self.out(r_out[:, -1, :])        # choose r_out at the last time step\n",
    "        return out\n",
    "\n",
    "\n",
    "# ----- Step 4: Instantiate ----- #\n",
    "\n",
    "rnn = RNN()\n",
    "print('\\n*** Model Information ***\\n', rnn, '\\n\\n*** Training Information ***')\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)\n",
    "loss_fn = nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
    "\n",
    "\n",
    "# ----- Step 5: Model Training ----- #\n",
    "\n",
    "for turns in range(1, 201):\n",
    "    for batch_idx, (train_x, train_y) in enumerate(train_loader):\n",
    "        \n",
    "        train_x = train_x.view(-1, TIME_STEP, INPUT_SIZE)\n",
    "        output = rnn(train_x)\n",
    "        loss = loss_fn(output, train_y)\n",
    "        optimizer.zero_grad()  # clear gradients for this training step\n",
    "        loss.backward()        # backward and compute gradients\n",
    "        optimizer.step()       # apply gradients\n",
    "\n",
    "        train_output = rnn(train_X)\n",
    "        pred_train_y = torch.max(train_output, 1)[1].data.numpy()\n",
    "        train_accuracy = float((pred_train_y == train_Y).astype(int).sum()) / float(train_Y.size)\n",
    "        train_loss = loss_fn(train_output, train_Y1)\n",
    "\n",
    "        torch.save(rnn, f'../Models/{NAME}/epoch_{turns}_{batch_idx}.pkl')\n",
    "        print('Epoch: ', turns, '_', batch_idx, '| train loss: %.4f' % train_loss.data.numpy(), '| train accuracy: %.2f' % train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1515152d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** The Optimum Model ***\n",
      "Epoch Index:  13 _ 0\n",
      "Train Loss: 0.102776 \n",
      "Train Accuracy: 0.9926 \n",
      "Test Accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Finding The Optimum Model Automatically\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "min_loss = 10000\n",
    "max_test_acc = 0\n",
    "corresponding_train_acc = 0\n",
    "\n",
    "turns_chosen = -1\n",
    "batch_idx_chosen = -1\n",
    "\n",
    "for turns in range(10, 19):\n",
    "    batch_number = int(train_X.shape[0]/BATCH_SIZE)\n",
    "    if train_X.shape[0] % BATCH_SIZE != 0:\n",
    "        batch_number += 1\n",
    "    \n",
    "    for batch_idx in range(batch_number):\n",
    "        rnn = torch.load(f'../Models/{NAME}/epoch_{turns}_{batch_idx}.pkl')\n",
    "        \n",
    "        train_output = rnn(train_X)\n",
    "        pred_train_y = torch.max(train_output, 1)[1].data.numpy()\n",
    "        train_accuracy = float((pred_train_y == train_Y).astype(int).sum()) / float(train_Y.size)\n",
    "        train_loss = loss_fn(train_output, train_Y1)\n",
    "        \n",
    "        test_output = rnn(test_X)\n",
    "        pred_test_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "        test_accuracy = float((pred_test_y == test_Y).astype(int).sum()) / float(test_Y.size)\n",
    "        \n",
    "        test_acc_bias = test_accuracy - max_test_acc\n",
    "        loss_bias = train_loss.data.numpy() - min_loss\n",
    "        if test_acc_bias >= 0.01 or (test_acc_bias >= 0 and test_acc_bias < 0.01 and loss_bias < 0.1):\n",
    "            max_test_acc = test_accuracy\n",
    "            min_loss = train_loss.data.numpy()\n",
    "            corresponding_train_acc = train_accuracy\n",
    "            turns_chosen = turns\n",
    "            batch_idx_chosen = batch_idx\n",
    "\n",
    "print('*** The Optimum Model ***\\nEpoch Index: ', turns_chosen, '_', batch_idx_chosen)\n",
    "print('Train Loss: %.6f' % min_loss, '\\nTrain Accuracy: %.4f' % corresponding_train_acc, '\\nTest Accuracy: %.4f' % max_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff6f06ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** FGSM ***\n",
      "\n",
      " Average Time Cost: 0.009563817697412828\n",
      "\n",
      " Success Rate of Adversarial Attack: 47.79 %\n",
      "\n",
      " Attacked RNN Test Accuracy: 0.7583\n",
      "\n",
      " Average Perturbation: tensor(88245.6562)\n",
      "\n",
      "*** DeepFool ***\n",
      "\n",
      " DeepFool_average_time_cost: 4.946950349737616\n",
      "\n",
      " Success Rate of Adversarial Attack: 47.79 %\n",
      "\n",
      " Attacked RNN Test Accuracy: 0.7583\n",
      "\n",
      " Average Perturbation: tensor(79016.4375)\n"
     ]
    }
   ],
   "source": [
    "import torchattacks\n",
    "\n",
    "\n",
    "print('*** FGSM ***')\n",
    "\n",
    "FGSM_time_part_start = time.time()\n",
    "attack_FGSM = torchattacks.FGSM(rnn, eps=0.007)\n",
    "adv_X_FGSM = attack_FGSM(train_X, torch.from_numpy(train_Y).to(torch.long))\n",
    "FGSM_time_part_stop = time.time()\n",
    "FGSM_average_time_cost = (FGSM_time_part_stop - FGSM_time_part_start) / adv_X_FGSM.shape[0]\n",
    "print('\\n Average Time Cost:', FGSM_average_time_cost)\n",
    "\n",
    "adv_output_FGSM = rnn(adv_X_FGSM)\n",
    "pred_adv_y_FGSM = torch.max(adv_output_FGSM, 1)[1].data.numpy()\n",
    "adv_accuracy_FGSM = float((pred_adv_y_FGSM == train_Y).astype(int).sum()) / float(train_Y.size)\n",
    "print('\\n Success Rate of Adversarial Attack: %.2f' % ((1-adv_accuracy_FGSM)*100), '%')\n",
    "\n",
    "test_acc_num = (pred_test_y == test_Y).astype(int).sum()\n",
    "adv_acc_num_FGSM = (pred_adv_y_FGSM == train_Y).astype(int).sum()\n",
    "test_adv_total_num_FGSM = test_Y.size + train_Y.size\n",
    "attacked_test_accuracy_FGSM = float(test_acc_num + adv_acc_num_FGSM) / float(test_adv_total_num_FGSM)\n",
    "print('\\n Attacked RNN Test Accuracy: %.4f' % attacked_test_accuracy_FGSM)\n",
    "\n",
    "sum_distance = 0\n",
    "for i in range(train_X.shape[0]):\n",
    "    for j in range(train_X.shape[1]):\n",
    "        sum_distance += abs(adv_X_FGSM[i, j, 0] - train_X[i, j, 0])\n",
    "average_distance = sum_distance / train_X.shape[0]\n",
    "print('\\n Average Perturbation:', average_distance)\n",
    "\n",
    "\n",
    "# print('\\n*** FAB ***')\n",
    "\n",
    "# FAB_time_part_start = time.time()\n",
    "# attack_FAB = torchattacks.FAB(rnn, norm='Linf', steps=1, eps=None, n_restarts=1, alpha_max=0.1, eta=1.05, beta=0.9, verbose=False, seed=0, targeted=False, n_classes=2)\n",
    "# adv_X_FAB = attack_FAB(train_X, torch.from_numpy(train_Y).to(torch.long))\n",
    "# FAB_time_part_stop = time.time()\n",
    "# FAB_average_time_cost = (FAB_time_part_stop - FAB_time_part_start) / adv_X_FAB.shape[0]\n",
    "# print('\\n FAB_average_time_cost:', FAB_average_time_cost)\n",
    "\n",
    "# adv_output_FAB = rnn(adv_X_FAB)\n",
    "# pred_adv_y_FAB = torch.max(adv_output_FAB, 1)[1].data.numpy()\n",
    "# adv_accuracy_FAB = float((pred_adv_y_FAB == train_Y).astype(int).sum()) / float(train_Y.size)\n",
    "# print('\\n Success Rate of Adversarial Attack: %.2f' % ((1-adv_accuracy_FAB)*100), '%')\n",
    "\n",
    "\n",
    "# test_acc_num = (pred_test_y == test_Y).astype(int).sum()\n",
    "# adv_acc_num_FAB = (pred_adv_y_FAB == train_Y).astype(int).sum()\n",
    "# test_adv_total_num_FAB = test_Y.size + train_Y.size\n",
    "# attacked_test_accuracy_FAB = float(test_acc_num + adv_acc_num_FAB) / float(test_adv_total_num_FAB)\n",
    "# print('\\n Attacked RNN Test Accuracy: %.4f' % attacked_test_accuracy_FAB)\n",
    "\n",
    "# sum_distance = 0\n",
    "# for i in range(train_X.shape[0]):\n",
    "#     for j in range(train_X.shape[1]):\n",
    "#         sum_distance += abs(adv_X_FAB[i, j, 0] - train_X[i, j, 0])\n",
    "# average_distance = sum_distance / train_X.shape[0]\n",
    "# print('\\n Average Perturbation:', average_distance)\n",
    "\n",
    "\n",
    "print('\\n*** DeepFool ***')\n",
    "\n",
    "DeepFool_time_part_start = time.time()\n",
    "attack_DeepFool = torchattacks.DeepFool(rnn, steps=50, overshoot=0.02)\n",
    "adv_X_DeepFool = attack_DeepFool(train_X, torch.from_numpy(train_Y).to(torch.long))\n",
    "DeepFool_time_part_stop = time.time()\n",
    "DeepFool_average_time_cost = (DeepFool_time_part_stop - DeepFool_time_part_start) / adv_X_DeepFool.shape[0]\n",
    "print('\\n DeepFool_average_time_cost:', DeepFool_average_time_cost)\n",
    "\n",
    "adv_output_DeepFool = rnn(adv_X_DeepFool)\n",
    "pred_adv_y_DeepFool = torch.max(adv_output_DeepFool, 1)[1].data.numpy()\n",
    "adv_accuracy_DeepFool = float((pred_adv_y_DeepFool == train_Y).astype(int).sum()) / float(train_Y.size)\n",
    "print('\\n Success Rate of Adversarial Attack: %.2f' % ((1-adv_accuracy_DeepFool)*100), '%')\n",
    "\n",
    "test_acc_num = (pred_test_y == test_Y).astype(int).sum()\n",
    "adv_acc_num_DeepFool = (pred_adv_y_DeepFool == train_Y).astype(int).sum()\n",
    "test_adv_total_num_DeepFool = test_Y.size + train_Y.size\n",
    "attacked_test_accuracy_DeepFool = float(test_acc_num + adv_acc_num_DeepFool) / float(test_adv_total_num_DeepFool)\n",
    "print('\\n Attacked RNN Test Accuracy: %.4f' % attacked_test_accuracy_DeepFool)\n",
    "\n",
    "sum_distance = 0\n",
    "for i in range(train_X.shape[0]):\n",
    "    for j in range(train_X.shape[1]):\n",
    "        sum_distance += abs(adv_X_DeepFool[i, j, 0] - train_X[i, j, 0])\n",
    "average_distance = sum_distance / train_X.shape[0]\n",
    "print('\\n Average Perturbation:', average_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64572275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18567.7930)\n",
      "tensor(85709.9531)\n"
     ]
    }
   ],
   "source": [
    "# Standard Range Distance\n",
    "\n",
    "low_0 = 16776960\n",
    "high_0 = 0\n",
    "low_1 = 16776960\n",
    "high_1 = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    current_sample = 0\n",
    "    for j in range(train_X.shape[1]):\n",
    "        current_sample += train_X[i, j, 0]\n",
    "    \n",
    "    if train_Y[i] == 0:\n",
    "        if current_sample > high_0:\n",
    "            high_0 = current_sample\n",
    "        if current_sample < low_0:\n",
    "            low_0 = current_sample\n",
    "            \n",
    "    if train_Y[i] == 1:\n",
    "        if current_sample > high_1:\n",
    "            high_1 = current_sample\n",
    "        if current_sample < low_1:\n",
    "            low_1 = current_sample\n",
    "\n",
    "range_distance_0 = high_0 - low_0\n",
    "range_distance_1 = high_1 - low_1\n",
    "\n",
    "print(range_distance_0)\n",
    "print(range_distance_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc1506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " FGSM Distance Rate: tensor(0.9679)\n",
      "\n",
      " DeepFool Distance Rate: tensor(0.8437)\n"
     ]
    }
   ],
   "source": [
    "# Over All\n",
    "\n",
    "self_count = 0\n",
    "other_count = 0\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    if train_Y[i] == 0:\n",
    "        self_range_distance = range_distance_0\n",
    "        other_range_distance = range_distance_1\n",
    "    else:\n",
    "        self_range_distance = range_distance_1\n",
    "        other_range_distance = range_distance_0\n",
    "    \n",
    "    for k in range(train_X.shape[0]):\n",
    "        if train_Y[i] == train_Y[k]:\n",
    "            self_count += 1\n",
    "            current_self_distance = 0\n",
    "            for j in range(train_X.shape[1]):\n",
    "                current_self_distance += abs(adv_X_FGSM[i, j, 0] - train_X[k, j, 0])\n",
    "            self_distance += current_self_distance / self_range_distance                \n",
    "        else:\n",
    "            other_count += 1\n",
    "            current_other_distance = 0\n",
    "            for j in range(train_X.shape[1]):\n",
    "                current_other_distance += abs(adv_X_FGSM[i, j, 0] - train_X[k, j, 0])\n",
    "            other_distance += current_other_distance / other_range_distance     \n",
    "\n",
    "distance_rate = (self_distance/self_count) / (other_distance/other_count)\n",
    "print('\\n FGSM Distance Rate:', distance_rate)\n",
    "\n",
    "\n",
    "self_count = 0\n",
    "other_count = 0\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    if train_Y[i] == 0:\n",
    "        self_range_distance = range_distance_0\n",
    "        other_range_distance = range_distance_1\n",
    "    else:\n",
    "        self_range_distance = range_distance_1\n",
    "        other_range_distance = range_distance_0\n",
    "    \n",
    "    for k in range(train_X.shape[0]):\n",
    "        if train_Y[i] == train_Y[k]:\n",
    "            self_count += 1\n",
    "            current_self_distance = 0\n",
    "            for j in range(train_X.shape[1]):\n",
    "                current_self_distance += abs(adv_X_DeepFool[i, j, 0] - train_X[k, j, 0])\n",
    "            self_distance += current_self_distance / self_range_distance                \n",
    "        else:\n",
    "            other_count += 1\n",
    "            current_other_distance = 0\n",
    "            for j in range(train_X.shape[1]):\n",
    "                current_other_distance += abs(adv_X_DeepFool[i, j, 0] - train_X[k, j, 0])\n",
    "            other_distance += current_other_distance / other_range_distance     \n",
    "\n",
    "distance_rate = (self_distance/self_count) / (other_distance/other_count)\n",
    "print('\\n DeepFool Distance Rate:', distance_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8950d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " FGSM Distance Rate: tensor(2.1331)\n",
      "\n",
      " DeepFool Distance Rate: tensor(1.8517)\n"
     ]
    }
   ],
   "source": [
    "# Only Adv\n",
    "\n",
    "self_count = 0\n",
    "other_count = 0\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    if pred_adv_y_FGSM[i] == train_Y[i]:\n",
    "        continue\n",
    "    \n",
    "    if train_Y[i] == 0:\n",
    "        self_range_distance = range_distance_0\n",
    "        other_range_distance = range_distance_1\n",
    "    else:\n",
    "        self_range_distance = range_distance_1\n",
    "        other_range_distance = range_distance_0\n",
    "    \n",
    "    for k in range(train_X.shape[0]):\n",
    "        if train_Y[i] == train_Y[k]:\n",
    "            self_count += 1\n",
    "            current_self_distance = 0\n",
    "            for j in range(train_X.shape[1]):\n",
    "                current_self_distance += abs(adv_X_FGSM[i, j, 0] - train_X[k, j, 0])\n",
    "            self_distance += current_self_distance / self_range_distance                \n",
    "        else:\n",
    "            other_count += 1\n",
    "            current_other_distance = 0\n",
    "            for j in range(train_X.shape[1]):\n",
    "                current_other_distance += abs(adv_X_FGSM[i, j, 0] - train_X[k, j, 0])\n",
    "            other_distance += current_other_distance / other_range_distance     \n",
    "\n",
    "distance_rate = (self_distance/self_count) / (other_distance/other_count)\n",
    "print('\\n FGSM Distance Rate:', distance_rate)\n",
    "\n",
    "\n",
    "self_count = 0\n",
    "other_count = 0\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    if pred_adv_y_DeepFool[i] == train_Y[i]:\n",
    "        continue\n",
    "    \n",
    "    if train_Y[i] == 0:\n",
    "        self_range_distance = range_distance_0\n",
    "        other_range_distance = range_distance_1\n",
    "    else:\n",
    "        self_range_distance = range_distance_1\n",
    "        other_range_distance = range_distance_0\n",
    "    \n",
    "    for k in range(train_X.shape[0]):\n",
    "        if train_Y[i] == train_Y[k]:\n",
    "            self_count += 1\n",
    "            current_self_distance = 0\n",
    "            for j in range(train_X.shape[1]):\n",
    "                current_self_distance += abs(adv_X_DeepFool[i, j, 0] - train_X[k, j, 0])\n",
    "            self_distance += current_self_distance / self_range_distance                \n",
    "        else:\n",
    "            other_count += 1\n",
    "            current_other_distance = 0\n",
    "            for j in range(train_X.shape[1]):\n",
    "                current_other_distance += abs(adv_X_DeepFool[i, j, 0] - train_X[k, j, 0])\n",
    "            other_distance += current_other_distance / other_range_distance     \n",
    "\n",
    "distance_rate = (self_distance/self_count) / (other_distance/other_count)\n",
    "print('\\n DeepFool Distance Rate:', distance_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e5495e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LABEL = 'GPOVY'\n",
    "timestep_record = [i for i in range(adv_X_FGSM.shape[1])]\n",
    "\n",
    "\n",
    "# plt.plot(timestep_record, train_X[87], '-', linewidth=3, color='#1f77b4', label='Original')\n",
    "# plt.plot(timestep_record, adv_X_FGSM[87], '-', linewidth=3, color='red', label='Attacked')\n",
    "# plt.xlabel(f\"{LABEL}-FGSM\")\n",
    "# plt.ylim(-50, 1550)\n",
    "# plt.legend()\n",
    "# plt.savefig(f'../Savefig/{LABEL}-FGSM.png', bbox_inches='tight', dpi=600)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(timestep_record, train_X[87], '.', color='#1f77b4', label='Original')\n",
    "# plt.plot(timestep_record, adv_X_DeepFool[87], '.', color='red', label='Attacked')\n",
    "# LABEL = 'DeepFool'\n",
    "# plt.xlabel(f\"{LABEL}-DeepFool\")\n",
    "# plt.ylim(-50, 1050)\n",
    "# plt.savefig(f'../Savefig/{LABEL}-DeepFool.png', bbox_inches='tight', dpi=600)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "plt.plot(timestep_record, train_X[87], '-', linewidth=3, color='#1f77b4', label='Original')\n",
    "plt.plot(timestep_record, adv_X_DeepFool[87], '-', linewidth=3, color='red', label='Attacked')\n",
    "plt.xlabel(f\"{LABEL}-DeepFool\")\n",
    "plt.ylim(-50, 1550)\n",
    "plt.legend()\n",
    "plt.savefig(f'../Savefig/{LABEL}-DeepFool.png', bbox_inches='tight', dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0a0e9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1555)\n",
      "tensor(1.1640)\n"
     ]
    }
   ],
   "source": [
    "print(self_distance/self_count)\n",
    "print(other_distance/other_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47ab7e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6356.8179)\n",
      "tensor(32528.4258)\n",
      "\n",
      " FGSM Cam Rate: tensor(2.3647)\n",
      "tensor(561.2692)\n",
      "tensor(237.3575)\n",
      "\n",
      " DeepFool Cam Rate: tensor(2.0197)\n",
      "tensor(401.4088)\n",
      "tensor(198.7464)\n"
     ]
    }
   ],
   "source": [
    "# Avg Sample and Avg Distance\n",
    "\n",
    "sum_train_X_0 = train_X[0] - train_X[0]\n",
    "sum_train_X_1 = train_X[0] - train_X[0]\n",
    "count_train_X_0 = 0\n",
    "count_train_X_1 = 0\n",
    "for i in range(train_X.shape[0]):\n",
    "    if train_Y[i] == 0:\n",
    "        count_train_X_0 += 1\n",
    "        sum_train_X_0 += train_X[i]\n",
    "    if train_Y[i] == 1:\n",
    "        count_train_X_1 += 1\n",
    "        sum_train_X_1 += train_X[i]\n",
    "avg_train_X_0 = sum_train_X_0 / count_train_X_0\n",
    "avg_train_X_1 = sum_train_X_1 / count_train_X_1\n",
    "\n",
    "distance_train_X_0 = 0\n",
    "distance_train_X_1 = 0\n",
    "for i in range(train_X.shape[0]):\n",
    "    current_distance = 0\n",
    "    if train_Y[i] == 0:\n",
    "        for j in range(train_X.shape[1]):\n",
    "            current_distance += abs(train_X[i, j, 0] - avg_train_X_0[j, 0])\n",
    "        distance_train_X_0 += current_distance\n",
    "    if train_Y[i] == 1:\n",
    "        for j in range(train_X.shape[1]):\n",
    "            current_distance += abs(train_X[i, j, 0] - avg_train_X_1[j, 0])\n",
    "        distance_train_X_1 += current_distance\n",
    "avg_distance_train_X_0 = distance_train_X_0 / count_train_X_0\n",
    "avg_distance_train_X_1 = distance_train_X_1 / count_train_X_1\n",
    "\n",
    "print(avg_distance_train_X_0)\n",
    "print(avg_distance_train_X_1)\n",
    "\n",
    "\n",
    "# Only Adv\n",
    "\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    if pred_adv_y_FGSM[i] == train_Y[i]:\n",
    "        continue\n",
    "\n",
    "    if train_Y[i] == 0:\n",
    "        self_avg_train_X = avg_train_X_0\n",
    "        other_avg_train_X = avg_train_X_1\n",
    "        self_avg_distance = avg_distance_train_X_0\n",
    "        other_avg_distance = avg_distance_train_X_1\n",
    "    else:\n",
    "        self_avg_train_X = avg_train_X_1\n",
    "        other_avg_train_X = avg_train_X_0\n",
    "        self_avg_distance = avg_distance_train_X_1\n",
    "        other_avg_distance = avg_distance_train_X_0\n",
    "\n",
    "    current_self_distance = 0\n",
    "    for j in range(train_X.shape[1]):\n",
    "        current_self_distance += abs(adv_X_FGSM[i, j, 0] - self_avg_train_X[j, 0])\n",
    "    self_distance += current_self_distance / self_avg_distance\n",
    "    \n",
    "    current_other_distance = 0\n",
    "    for j in range(train_X.shape[1]):\n",
    "        current_other_distance += abs(adv_X_FGSM[i, j, 0] - other_avg_train_X[j, 0])\n",
    "    other_distance += current_other_distance / other_avg_distance\n",
    "\n",
    "cam_rate =  self_distance / other_distance\n",
    "print('\\n FGSM Cam Rate:', cam_rate)\n",
    "print(self_distance)\n",
    "print(other_distance)\n",
    "\n",
    "\n",
    "self_distance = 0\n",
    "other_distance = 0\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    if pred_adv_y_DeepFool[i] == train_Y[i]:\n",
    "        continue\n",
    "\n",
    "    if train_Y[i] == 0:\n",
    "        self_avg_train_X = avg_train_X_0\n",
    "        other_avg_train_X = avg_train_X_1\n",
    "        self_avg_distance = avg_distance_train_X_0\n",
    "        other_avg_distance = avg_distance_train_X_1\n",
    "    else:\n",
    "        self_avg_train_X = avg_train_X_1\n",
    "        other_avg_train_X = avg_train_X_0\n",
    "        self_avg_distance = avg_distance_train_X_1\n",
    "        other_avg_distance = avg_distance_train_X_0\n",
    "\n",
    "    current_self_distance = 0\n",
    "    for j in range(train_X.shape[1]):\n",
    "        current_self_distance += abs(adv_X_DeepFool[i, j, 0] - self_avg_train_X[j, 0])\n",
    "    self_distance += current_self_distance / self_avg_distance\n",
    "    \n",
    "    current_other_distance = 0\n",
    "    for j in range(train_X.shape[1]):\n",
    "        current_other_distance += abs(adv_X_DeepFool[i, j, 0] - other_avg_train_X[j, 0])\n",
    "    other_distance += current_other_distance / other_avg_distance\n",
    "\n",
    "cam_rate =  self_distance / other_distance\n",
    "print('\\n DeepFool Cam Rate:', cam_rate)\n",
    "print(self_distance)\n",
    "print(other_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75fd473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
